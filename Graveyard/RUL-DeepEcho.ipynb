{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc2717f",
   "metadata": {},
   "source": [
    "# RUL prediction based on synthetic training data\n",
    "In this notebook we will perform RUL prediction on CMAPSS data, but instead of using the original data we use a synthetic variant. The generation of synthetic data is performed in [this notebook](). The baseline and some introduction on RUL prediction is found in [this notebook]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2629af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import various modules and packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84a34f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>ops_set1</th>\n",
       "      <th>ops_set2</th>\n",
       "      <th>ops_set3</th>\n",
       "      <th>sens_1</th>\n",
       "      <th>sens_2</th>\n",
       "      <th>sens_3</th>\n",
       "      <th>sens_4</th>\n",
       "      <th>sens_5</th>\n",
       "      <th>sens_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sens_12</th>\n",
       "      <th>sens_13</th>\n",
       "      <th>sens_14</th>\n",
       "      <th>sens_15</th>\n",
       "      <th>sens_16</th>\n",
       "      <th>sens_17</th>\n",
       "      <th>sens_18</th>\n",
       "      <th>sens_19</th>\n",
       "      <th>sens_20</th>\n",
       "      <th>sens_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>194</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.24</td>\n",
       "      <td>1599.45</td>\n",
       "      <td>1415.79</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>520.69</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8213.28</td>\n",
       "      <td>8.4715</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>195</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1595.69</td>\n",
       "      <td>1422.05</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.05</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8210.85</td>\n",
       "      <td>8.4512</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>196</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.44</td>\n",
       "      <td>1593.15</td>\n",
       "      <td>1406.82</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.18</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8217.24</td>\n",
       "      <td>8.4569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>197</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.26</td>\n",
       "      <td>1594.99</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.33</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8220.48</td>\n",
       "      <td>8.4711</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13096 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_nr  ops_set1  ops_set2  ops_set3  sens_1  sens_2   sens_3   sens_4  \\\n",
       "1          1    0.0023    0.0003     100.0  518.67  643.02  1585.29  1398.21   \n",
       "1          2   -0.0027   -0.0003     100.0  518.67  641.71  1588.45  1395.42   \n",
       "1          3    0.0003    0.0001     100.0  518.67  642.46  1586.94  1401.34   \n",
       "1          4    0.0042    0.0000     100.0  518.67  642.44  1584.12  1406.42   \n",
       "1          5    0.0014    0.0000     100.0  518.67  642.51  1587.19  1401.92   \n",
       "..       ...       ...       ...       ...     ...     ...      ...      ...   \n",
       "100      194    0.0049    0.0000     100.0  518.67  643.24  1599.45  1415.79   \n",
       "100      195   -0.0011   -0.0001     100.0  518.67  643.22  1595.69  1422.05   \n",
       "100      196   -0.0006   -0.0003     100.0  518.67  643.44  1593.15  1406.82   \n",
       "100      197   -0.0038    0.0001     100.0  518.67  643.26  1594.99  1419.36   \n",
       "100      198    0.0013    0.0003     100.0  518.67  642.95  1601.62  1424.99   \n",
       "\n",
       "     sens_5  sens_6  ...  sens_12  sens_13  sens_14  sens_15  sens_16  \\\n",
       "1     14.62   21.61  ...   521.72  2388.03  8125.55   8.4052     0.03   \n",
       "1     14.62   21.61  ...   522.16  2388.06  8139.62   8.3803     0.03   \n",
       "1     14.62   21.61  ...   521.97  2388.03  8130.10   8.4441     0.03   \n",
       "1     14.62   21.61  ...   521.38  2388.05  8132.90   8.3917     0.03   \n",
       "1     14.62   21.61  ...   522.15  2388.03  8129.54   8.4031     0.03   \n",
       "..      ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "100   14.62   21.61  ...   520.69  2388.00  8213.28   8.4715     0.03   \n",
       "100   14.62   21.61  ...   521.05  2388.09  8210.85   8.4512     0.03   \n",
       "100   14.62   21.61  ...   521.18  2388.04  8217.24   8.4569     0.03   \n",
       "100   14.62   21.61  ...   521.33  2388.08  8220.48   8.4711     0.03   \n",
       "100   14.62   21.61  ...   521.07  2388.05  8214.64   8.4903     0.03   \n",
       "\n",
       "     sens_17  sens_18  sens_19  sens_20  sens_21  \n",
       "1        392     2388    100.0    38.86  23.3735  \n",
       "1        393     2388    100.0    39.02  23.3916  \n",
       "1        393     2388    100.0    39.08  23.4166  \n",
       "1        391     2388    100.0    39.00  23.3737  \n",
       "1        390     2388    100.0    38.99  23.4130  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "100      394     2388    100.0    38.65  23.1974  \n",
       "100      395     2388    100.0    38.57  23.2771  \n",
       "100      395     2388    100.0    38.62  23.2051  \n",
       "100      395     2388    100.0    38.66  23.2699  \n",
       "100      396     2388    100.0    38.70  23.1855  \n",
       "\n",
       "[13096 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the synthetic data as training data\n",
    "train = pd.read_csv('./CMAPSS/Synthetic/DeepEcho_FD001_RUL.csv')\n",
    "train = train.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# include all columns apart from RUL\n",
    "col_names = train.columns[:-1]\n",
    "\n",
    "# read data\n",
    "test_data = pd.read_csv(('./CMAPSS/test_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "test_labels = pd.read_csv(('./CMAPSS/RUL_FD001.txt'), sep='\\s+', header=None, names=['RUL'])\n",
    "\n",
    "# show synthetic data\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dc0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Remaining Useful Life (RUL) for each index (engine)\n",
    "def add_remaining_useful_life(df):\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "    max_cycle = grouped_by_unit[\"timecycle\"].max()\n",
    "    \n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "    \n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"timecycle\"]\n",
    "    result_frame[\"RUL\"] = remaining_useful_life\n",
    "    \n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame\n",
    "\n",
    "# train = add_remaining_useful_life(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723a262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set after removal of constant values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sens_2</th>\n",
       "      <th>sens_3</th>\n",
       "      <th>sens_4</th>\n",
       "      <th>sens_7</th>\n",
       "      <th>sens_8</th>\n",
       "      <th>sens_9</th>\n",
       "      <th>sens_11</th>\n",
       "      <th>sens_12</th>\n",
       "      <th>sens_13</th>\n",
       "      <th>sens_14</th>\n",
       "      <th>sens_15</th>\n",
       "      <th>sens_17</th>\n",
       "      <th>sens_20</th>\n",
       "      <th>sens_21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642.473068</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1411.264748</td>\n",
       "      <td>553.620924</td>\n",
       "      <td>2387.983560</td>\n",
       "      <td>9066.693171</td>\n",
       "      <td>47.541168</td>\n",
       "      <td>521.428812</td>\n",
       "      <td>2388.100523</td>\n",
       "      <td>8173.048289</td>\n",
       "      <td>8.442146</td>\n",
       "      <td>392.952618</td>\n",
       "      <td>38.901845</td>\n",
       "      <td>23.289705</td>\n",
       "      <td>84.186201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.901593</td>\n",
       "      <td>1592.297732</td>\n",
       "      <td>1399.935190</td>\n",
       "      <td>553.624768</td>\n",
       "      <td>2388.133781</td>\n",
       "      <td>9078.790032</td>\n",
       "      <td>47.541168</td>\n",
       "      <td>521.411841</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8153.491199</td>\n",
       "      <td>8.455641</td>\n",
       "      <td>392.893241</td>\n",
       "      <td>39.019725</td>\n",
       "      <td>23.270599</td>\n",
       "      <td>101.649576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.488421</td>\n",
       "      <td>1589.557587</td>\n",
       "      <td>1413.170862</td>\n",
       "      <td>553.297483</td>\n",
       "      <td>2388.110799</td>\n",
       "      <td>9069.687832</td>\n",
       "      <td>47.839807</td>\n",
       "      <td>520.937211</td>\n",
       "      <td>2388.112223</td>\n",
       "      <td>8140.691979</td>\n",
       "      <td>8.471263</td>\n",
       "      <td>392.541833</td>\n",
       "      <td>38.862521</td>\n",
       "      <td>23.289705</td>\n",
       "      <td>93.164509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.377192</td>\n",
       "      <td>1586.122690</td>\n",
       "      <td>1411.388159</td>\n",
       "      <td>553.507911</td>\n",
       "      <td>2388.157503</td>\n",
       "      <td>9088.595165</td>\n",
       "      <td>47.421999</td>\n",
       "      <td>521.274816</td>\n",
       "      <td>2388.117313</td>\n",
       "      <td>8145.023711</td>\n",
       "      <td>8.394715</td>\n",
       "      <td>393.828368</td>\n",
       "      <td>38.730699</td>\n",
       "      <td>23.233689</td>\n",
       "      <td>96.976067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.695678</td>\n",
       "      <td>1591.227074</td>\n",
       "      <td>1410.420718</td>\n",
       "      <td>553.427153</td>\n",
       "      <td>2388.084332</td>\n",
       "      <td>9064.356090</td>\n",
       "      <td>47.414871</td>\n",
       "      <td>521.698415</td>\n",
       "      <td>2388.100825</td>\n",
       "      <td>8130.063203</td>\n",
       "      <td>8.435684</td>\n",
       "      <td>393.670542</td>\n",
       "      <td>38.756972</td>\n",
       "      <td>23.335115</td>\n",
       "      <td>91.736228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>642.401271</td>\n",
       "      <td>1593.685517</td>\n",
       "      <td>1413.238487</td>\n",
       "      <td>553.279646</td>\n",
       "      <td>2388.125408</td>\n",
       "      <td>9067.512259</td>\n",
       "      <td>47.523497</td>\n",
       "      <td>521.586056</td>\n",
       "      <td>2388.122424</td>\n",
       "      <td>8138.288461</td>\n",
       "      <td>8.462023</td>\n",
       "      <td>394.808076</td>\n",
       "      <td>38.952301</td>\n",
       "      <td>23.291737</td>\n",
       "      <td>124.881773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>642.571931</td>\n",
       "      <td>1589.853140</td>\n",
       "      <td>1412.539083</td>\n",
       "      <td>553.286837</td>\n",
       "      <td>2388.087885</td>\n",
       "      <td>9068.586140</td>\n",
       "      <td>47.495900</td>\n",
       "      <td>521.148832</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8151.826193</td>\n",
       "      <td>8.431912</td>\n",
       "      <td>392.546345</td>\n",
       "      <td>38.911342</td>\n",
       "      <td>23.273871</td>\n",
       "      <td>109.955212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>642.353279</td>\n",
       "      <td>1588.698769</td>\n",
       "      <td>1410.207921</td>\n",
       "      <td>552.365619</td>\n",
       "      <td>2388.107631</td>\n",
       "      <td>9081.744072</td>\n",
       "      <td>47.751174</td>\n",
       "      <td>520.750551</td>\n",
       "      <td>2388.083559</td>\n",
       "      <td>8126.134846</td>\n",
       "      <td>8.433762</td>\n",
       "      <td>392.104497</td>\n",
       "      <td>38.825385</td>\n",
       "      <td>23.338452</td>\n",
       "      <td>126.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25724</th>\n",
       "      <td>642.819208</td>\n",
       "      <td>1587.417323</td>\n",
       "      <td>1408.486266</td>\n",
       "      <td>553.411608</td>\n",
       "      <td>2388.105514</td>\n",
       "      <td>9083.899100</td>\n",
       "      <td>47.633874</td>\n",
       "      <td>521.486042</td>\n",
       "      <td>2388.103948</td>\n",
       "      <td>8155.002869</td>\n",
       "      <td>8.434369</td>\n",
       "      <td>393.644056</td>\n",
       "      <td>38.757235</td>\n",
       "      <td>23.357953</td>\n",
       "      <td>107.807862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25725</th>\n",
       "      <td>642.853745</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1406.385163</td>\n",
       "      <td>552.671225</td>\n",
       "      <td>2388.128769</td>\n",
       "      <td>9058.025012</td>\n",
       "      <td>47.700664</td>\n",
       "      <td>521.363182</td>\n",
       "      <td>2388.031543</td>\n",
       "      <td>8137.568565</td>\n",
       "      <td>8.431172</td>\n",
       "      <td>393.416130</td>\n",
       "      <td>38.601349</td>\n",
       "      <td>23.310760</td>\n",
       "      <td>75.243916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25726 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sens_2       sens_3       sens_4      sens_7       sens_8  \\\n",
       "0      642.473068  1590.523119  1411.264748  553.620924  2387.983560   \n",
       "1      642.901593  1592.297732  1399.935190  553.624768  2388.133781   \n",
       "2      642.488421  1589.557587  1413.170862  553.297483  2388.110799   \n",
       "3      642.377192  1586.122690  1411.388159  553.507911  2388.157503   \n",
       "4      642.695678  1591.227074  1410.420718  553.427153  2388.084332   \n",
       "...           ...          ...          ...         ...          ...   \n",
       "25721  642.401271  1593.685517  1413.238487  553.279646  2388.125408   \n",
       "25722  642.571931  1589.853140  1412.539083  553.286837  2388.087885   \n",
       "25723  642.353279  1588.698769  1410.207921  552.365619  2388.107631   \n",
       "25724  642.819208  1587.417323  1408.486266  553.411608  2388.105514   \n",
       "25725  642.853745  1590.523119  1406.385163  552.671225  2388.128769   \n",
       "\n",
       "            sens_9    sens_11     sens_12      sens_13      sens_14   sens_15  \\\n",
       "0      9066.693171  47.541168  521.428812  2388.100523  8173.048289  8.442146   \n",
       "1      9078.790032  47.541168  521.411841  2388.096152  8153.491199  8.455641   \n",
       "2      9069.687832  47.839807  520.937211  2388.112223  8140.691979  8.471263   \n",
       "3      9088.595165  47.421999  521.274816  2388.117313  8145.023711  8.394715   \n",
       "4      9064.356090  47.414871  521.698415  2388.100825  8130.063203  8.435684   \n",
       "...            ...        ...         ...          ...          ...       ...   \n",
       "25721  9067.512259  47.523497  521.586056  2388.122424  8138.288461  8.462023   \n",
       "25722  9068.586140  47.495900  521.148832  2388.096152  8151.826193  8.431912   \n",
       "25723  9081.744072  47.751174  520.750551  2388.083559  8126.134846  8.433762   \n",
       "25724  9083.899100  47.633874  521.486042  2388.103948  8155.002869  8.434369   \n",
       "25725  9058.025012  47.700664  521.363182  2388.031543  8137.568565  8.431172   \n",
       "\n",
       "          sens_17    sens_20    sens_21         RUL  \n",
       "0      392.952618  38.901845  23.289705   84.186201  \n",
       "1      392.893241  39.019725  23.270599  101.649576  \n",
       "2      392.541833  38.862521  23.289705   93.164509  \n",
       "3      393.828368  38.730699  23.233689   96.976067  \n",
       "4      393.670542  38.756972  23.335115   91.736228  \n",
       "...           ...        ...        ...         ...  \n",
       "25721  394.808076  38.952301  23.291737  124.881773  \n",
       "25722  392.546345  38.911342  23.273871  109.955212  \n",
       "25723  392.104497  38.825385  23.338452  126.050395  \n",
       "25724  393.644056  38.757235  23.357953  107.807862  \n",
       "25725  393.416130  38.601349  23.310760   75.243916  \n",
       "\n",
       "[25726 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data, remove constant columns, indexes and operational settings.\n",
    "print(\"Train set after removal of constant values:\")\n",
    "const_cols = ['sens_1', 'sens_5', 'sens_6', 'sens_10', 'sens_16', 'sens_18', 'sens_19']\n",
    "\n",
    "op_settings = [\"ops_set1\", \"ops_set2\", \"ops_set3\"]\n",
    "\n",
    "cols_to_drop = [\"unit_nr\"] + op_settings + const_cols\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd94f39",
   "metadata": {},
   "source": [
    "# Prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd00222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc18b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove RUL from training data, split\n",
    "train_data = train.drop('RUL', axis=1) # data without constants\n",
    "train_labels = train.pop('RUL') # RUL values\n",
    "\n",
    "# Since the true RUL values for the test set are only provided for the last time cycle of each engine, \n",
    "# the test set is subsetted to represent the same\n",
    "test_data = test_data.groupby('unit_nr').last().reset_index().drop(cols_to_drop, axis=1)\n",
    "\n",
    "# # check whether RUL and constant columns removed\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a44ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:9.913156983258949, R2:0.6496482594793125\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [303, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m evaluate(pred_train, train_labels, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(y_true, y_hat, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(y_true, y_hat, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n\u001b[1;32m      4\u001b[0m     variance \u001b[38;5;241m=\u001b[39m r2_score(y_true, y_hat)\n",
      "File \u001b[0;32m~/anaconda3/envs/KLM/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[1;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    384\u001b[0m ):\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/KLM/lib/python3.9/site-packages/sklearn/metrics/_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/KLM/lib/python3.9/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [303, 100]"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf.fit(train_data, train_labels)\n",
    "\n",
    "# predict and evaluate\n",
    "pred_train = rf.predict(train_data)\n",
    "evaluate(pred_train, train_labels, 'train')\n",
    "\n",
    "pred_test = rf.predict(test_data)\n",
    "evaluate(pred_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680a786",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "First of all, we see that the RMSE is way higher than expected. As we were struggling at first with finding a synthetic data generator that can correctly model timeseries, we expect this may be a cause. To check this hypothesis, we will plot the difference sensors compared to RUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e705ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload synthetic data\n",
    "train = pd.read_csv('./CMAPSS/Synthetic/SDV_FD001_RUL.csv')\n",
    "train = train.drop('Unnamed: 0', axis=1)\n",
    "train = add_remaining_useful_life(train)\n",
    "\n",
    "# create list with sensors\n",
    "sensors = []\n",
    "for i in range(1,22):\n",
    "    sensors.append(f\"sens_{i}\")\n",
    "\n",
    "# create plot\n",
    "fig, axs = plt.subplots(nrows=7, ncols=3, figsize=(15, 24))\n",
    "\n",
    "for i, sensor_idx in enumerate(sensors):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axs[row, col]\n",
    "    # plot each sensor in own graph\n",
    "    for j in train['unit_nr'].unique():\n",
    "        ax.plot('RUL', sensor_idx, data=train[train['unit_nr']==j])\n",
    "    \n",
    "    # graphics\n",
    "    ax.set_xlim(250, 0)\n",
    "    ax.set_xticks(np.arange(0, 275, 25))\n",
    "    ax.set_ylabel(sensor_idx)\n",
    "    ax.set_xlabel(f'RUL set out to value of {sensor_idx}.')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/Obtained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, axs = plt.subplots(nrows=7, ncols=3, figsize=(15, 24))\n",
    "\n",
    "# Compute Remaining Useful Life (RUL) for each index (engine)\n",
    "def add_remaining_useful_life(df):\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "    max_cycle = grouped_by_unit[\"timecycle\"].max()\n",
    "    \n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "    \n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"timecycle\"]\n",
    "    result_frame[\"RUL\"] = remaining_useful_life\n",
    "    \n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame\n",
    "\n",
    "syn_data = train\n",
    "data = pd.read_csv(('./CMAPSS/train_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "data = add_remaining_useful_life(data)\n",
    "\n",
    "for i, sensor_idx in enumerate(sensors):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axs[row, col]\n",
    "    # plot each sensor in own graph\n",
    "    ax.plot('RUL', sensor_idx, data=syn_data[syn_data['unit_nr']==297], label='Synthetic')\n",
    "    ax.plot('RUL', sensor_idx, data=data[data['unit_nr']==1], label='Original')\n",
    "    \n",
    "    # graphics\n",
    "    ax.set_xlim(250, 0)\n",
    "    ax.set_xticks(np.arange(0, 275, 25))\n",
    "    ax.set_ylabel(sensor_idx)\n",
    "    ax.set_xlabel(f'RUL set out to value of {sensor_idx}.')\n",
    "\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig('./Figures/Syn-vs-Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40b30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
