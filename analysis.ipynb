{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# install DataSynthesizer (cannot be included in conda)\n",
    "!pip install DataSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import DataSynthesizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94511920",
   "metadata": {},
   "source": [
    "# Read & preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ac969",
   "metadata": {},
   "source": [
    "We read the data from the CMAPPS folder. We remove the last two columns as these solely contain N/A values and then we rename the columns with their respective names as defined in \"readme.txt\".\n",
    "We then store the data as a comma-separated-value (csv) file instead of a text file with tabs, as DataSynthesizer works with csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CMAPSS/train_FD001.txt', sep=\" \", header=None)\n",
    "\n",
    "# drop last two columns with N/A values\n",
    "data = data.iloc[:, :-2]\n",
    "\n",
    "# rename columns according to readme.txt\n",
    "col_names = [\"unit-nr\", \"timecycle\", \"ops-set1\", \"ops-set2\", \"ops-set3\"]\n",
    "for i in range(1,22):\n",
    "    col_names.append(f\"sens-{i}\")\n",
    "data.columns = col_names\n",
    "data.to_csv('CMAPSS/train_FD001_pre.csv', index=False)\n",
    "\n",
    "data_length = len(data)\n",
    "\n",
    "# display data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b60e4f",
   "metadata": {},
   "source": [
    "## Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the synthetic data using the Git page from DataSynthesizer\n",
    "https://github.com/DataResponsibly/DataSynthesizer/blob/master/notebooks/DataSynthesizer__correlated_attribute_mode.ipynb\n",
    "\n",
    "NOTE: First create the description file (e.g. via terminal command touch)\n",
    "before running the code, does not write the .json file itself.\n",
    "\"\"\"\n",
    "\n",
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "\n",
    "def create_data_adult(data_length):\n",
    "    # input dataset\n",
    "    input_data = 'CMAPSS/train_FD001_pre.csv'\n",
    "\n",
    "    # location of two output files\n",
    "    mode = 'correlated_attribute_mode'\n",
    "    description_file = f'./CMAPSS/Synthetic/description_FD001.json'\n",
    "    synthetic_data = f'./CMAPSS/Synthetic/synthetic_data_FD001.csv'\n",
    "\n",
    "    # An attribute is categorical if its domain size is less than this threshold.\n",
    "    threshold_value = 42\n",
    "\n",
    "    # A parameter in Differential Privacy. It roughly means that removing a row in the input dataset will not \n",
    "    # change the probability of getting the same output more than a multiplicative difference of exp(epsilon).\n",
    "    # Increase epsilon value to reduce the injected noises. Set epsilon=0 to turn off differential privacy.\n",
    "    epsilon = 0\n",
    "\n",
    "    # The maximum number of parents in Bayesian network, i.e., the maximum number of incoming edges.\n",
    "    degree_of_bayesian_network = 2\n",
    "\n",
    "    # Number of tuples generated in synthetic dataset.\n",
    "    num_tuples_to_generate = data_length\n",
    "\n",
    "    describer = DataDescriber(category_threshold=threshold_value)\n",
    "    describer.describe_dataset_in_correlated_attribute_mode(dataset_file=input_data, \n",
    "                                                            epsilon=epsilon, \n",
    "                                                            k=degree_of_bayesian_network)\n",
    "    describer.save_dataset_description_to_file(description_file)\n",
    "\n",
    "    # Generate data set\n",
    "    generator = DataGenerator()\n",
    "    generator.generate_dataset_in_correlated_attribute_mode(num_tuples_to_generate, description_file)\n",
    "    generator.save_synthetic_data(synthetic_data)\n",
    "\n",
    "create_data_adult(data_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a7d1d",
   "metadata": {},
   "source": [
    "# Read & output synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_data = pd.read_csv('./CMAPSS/Synthetic/synthetic_data_FD001.csv')\n",
    "syn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
